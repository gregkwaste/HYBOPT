{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_numbers = [2, 3, 4]\n",
    "t_values = [60, 80, 100]\n",
    "msop_folder_path = \"./MSOP_datasets/over_100/\"\n",
    "#msop_folder_path = \"./MSOP_datasets/all/\"\n",
    "sop_folder_path = \"./SOP_non_random_datasets/\"\n",
    "msop_comment_add = \"SOP::[From Archetti, Carrabs, Cerulli. The set orienteering problem. (2018).]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(dataset_path, t_value):\n",
    "    sop_lines = SOPDatasetLines()\n",
    "    #print(dataset_path)\n",
    "    #print(sop_lines)\n",
    "    split_sop_file(dataset_path, sop_lines)\n",
    "    sop_lines.check_lines()\n",
    "    for vehicles in vehicle_numbers:\n",
    "        create_msop_dataset(dataset_path, vehicles, sop_lines, t_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msop_dataset(dataset_path, vehicle_number, sop_lines, t_value):\n",
    "    msop_dataset_name = transform_name(dataset_path, vehicle_number)\n",
    "    #msop_f = open(msop_folder_path + f\"t_{t_value}_v_{vehicle_number}/\"+ msop_dataset_name + \".msop\", \"w\")\n",
    "    msop_f = open(msop_folder_path + \"/\" + msop_dataset_name + \".msop\", \"w\")\n",
    "\n",
    "    # === NAME ===\n",
    "    msop_name_line = \"NAME: \" + msop_dataset_name + \"\\n\"\n",
    "    msop_f.write(msop_name_line)\n",
    "    # === VEHICLES ===\n",
    "    msop_vehicles_line = \"VEHICLES: \" + str(vehicle_number) + \"\\n\"\n",
    "    msop_f.write(msop_vehicles_line)\n",
    "    # === COMMENT ===\n",
    "    msop_comment_line = \" \".join([sop_lines.comment_line[:-1], msop_comment_add]) + \"\\n\" #[:-2] in order not to include the \\n\n",
    "    msop_f.write(msop_comment_line)\n",
    "    # === TYPE ===\n",
    "    msop_type_line = sop_lines.type_line\n",
    "    msop_f.write(msop_type_line)\n",
    "    # === DIMENSION ===\n",
    "    msop_dimension_line = sop_lines.dimension_line\n",
    "    msop_f.write(msop_dimension_line)\n",
    "    # === TMAX ===\n",
    "    sop_tmax = int(sop_lines.tmax_line[:-1].split(\" \")[-1]) # get the tmax number\n",
    "    if t_value in set([60, 80, 100]):\n",
    "        msop_tmax = math.ceil(sop_tmax / vehicle_number)\n",
    "    else:\n",
    "        msop_tmax = math.ceil(sop_tmax / vehicle_number * t_value / 100)\n",
    "    msop_tmax_line = \"TMAX: \" + str(msop_tmax) + \"\\n\"\n",
    "    msop_f.write(msop_tmax_line)\n",
    "    # === START_SET ===\n",
    "    msop_start_set_line = sop_lines.start_set_line\n",
    "    msop_f.write(msop_start_set_line)\n",
    "    # === END_SET ===\n",
    "    msop_end_set_line = sop_lines.end_set_line\n",
    "    msop_f.write(msop_end_set_line)\n",
    "    # === SETS ===\n",
    "    msop_sets_line = sop_lines.sets_line\n",
    "    msop_f.write(msop_sets_line)\n",
    "    # === EDGE_WEIGHT_TYPE ===\n",
    "    msop_edge_weight_type_line = sop_lines.edge_weight_type_line\n",
    "    msop_f.write(msop_edge_weight_type_line)\n",
    "    # === NODE_COORD_SECTION ===\n",
    "    msop_node_coord_section_line = sop_lines.node_coord_section_line\n",
    "    msop_f.write(msop_node_coord_section_line)\n",
    "    # === GTSP_SET_SECTION ===\n",
    "    msop_gtsp_set_section_line = sop_lines.gtsp_set_section_line\n",
    "    msop_f.write(msop_gtsp_set_section_line)\n",
    "\n",
    "    # close file\n",
    "    msop_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_till_substring(text, delimeters):\n",
    "    if isinstance(delimeters, list):\n",
    "        delimeters = \"|\".join(delimeters)\n",
    "    #print(text)\n",
    "    #print(delimeters)\n",
    "    text_to_get = re.split(delimeters, text)[0]\n",
    "    #print(text_to_get)\n",
    "    #remained_text = text.removeprefix(text_to_get) # for python v>3.9\n",
    "    remained_text = text\n",
    "    if text.startswith(text_to_get):\n",
    "        remained_text = text[len(text_to_get):]\n",
    "    #remained_text = re.split(delimeters, text)[1] \n",
    "    #print(remained_text)\n",
    "    return text_to_get, remained_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name(dataset_path, vehicle_number):\n",
    "    dataset_name = dataset_path.split(\"\\\\\")[1][:-4]\n",
    "    gtsp_dataset_name, time_pct, profit_type = dataset_name.split(\"_\")\n",
    "    msop_dataset_name = \"_\".join([gtsp_dataset_name, time_pct, profit_type ,\"v\" + str(vehicle_number)])\n",
    "    return msop_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOPDatasetLines:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def check_lines(self):\n",
    "        if (not self.name_line.startswith(\"NAME\")):\n",
    "            raise Exception(\"Name line error.\")\n",
    "        elif (not self.type_line.startswith(\"TYPE\")):\n",
    "            raise Exception(\"Type line error.\")\n",
    "        elif (not self.comment_line.startswith(\"COMMENT\")):\n",
    "            raise Exception(\"Comment line error.\")\n",
    "        elif (not self.dimension_line.startswith(\"DIMENSION\")):\n",
    "            raise Exception(\"Dimension line error.\")\n",
    "        elif (not self.tmax_line.startswith(\"TMAX\")):\n",
    "            raise Exception(\"Tmax line error.\")\n",
    "        elif (not self.start_set_line.startswith(\"START_SET\")):\n",
    "            raise Exception(\"Start set line error.\")\n",
    "        elif (not self.end_set_line.startswith(\"END_SET\")):\n",
    "            raise Exception(\"End set line error.\")\n",
    "        elif (not self.sets_line.startswith(\"SETS\")):\n",
    "            raise Exception(\"Sets line error.\")\n",
    "        elif (not self.edge_weight_type_line.startswith(\"EDGE_WEIGHT_TYPE\")):\n",
    "            raise Exception(\"Edge weight type line error.\")\n",
    "        elif (not self.node_coord_section_line.startswith(\"NODE_COORD_SECTION\")):\n",
    "            raise Exception(\"Node coord section line error.\")\n",
    "        elif (not self.gtsp_set_section_line.startswith(\"GTSP_SET_SECTION\")):\n",
    "            raise Exception(\"GTSP set section line error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sop_file(dataset_path, sop_lines):\n",
    "    sop_f = open(dataset_path, \"r\")\n",
    "    sop_f_text = sop_f.read()\n",
    "    #print(sop_f_text)\n",
    "    # === NAME ===\n",
    "    sop_lines.name_line, remained_text = get_text_till_substring(sop_f_text, [\"TYPE\", \"COMMENT\"])\n",
    "    # === TYPE, COMMENT ===\n",
    "    if remained_text.startswith(\"TYPE\"):\n",
    "        sop_lines.type_line, remained_text = get_text_till_substring(remained_text, \"COMMENT\")\n",
    "        sop_lines.comment_line, remained_text = get_text_till_substring(remained_text, \"DIMENSION\")\n",
    "    elif remained_text.startswith(\"COMMENT\"):\n",
    "        sop_lines.comment_line, remained_text = get_text_till_substring(remained_text, \"TYPE\")\n",
    "        sop_lines.type_line, remained_text = get_text_till_substring(remained_text, \"DIMENSION\")\n",
    "    else:\n",
    "        raise Exception(\"Neither type nor comment in the second line.\")\n",
    "    # === DIMENSION ==\n",
    "    sop_lines.dimension_line, remained_text = get_text_till_substring(remained_text, \"TMAX\")\n",
    "    # === TMAX ==\n",
    "    sop_lines.tmax_line, remained_text = get_text_till_substring(remained_text, \"START_SET\")\n",
    "    # === START_SET ==\n",
    "    sop_lines.start_set_line, remained_text = get_text_till_substring(remained_text, \"END_SET\")\n",
    "    # === END_SET ==\n",
    "    sop_lines.end_set_line, remained_text = get_text_till_substring(remained_text, \"SETS\")\n",
    "    # === SETS ==\n",
    "    sop_lines.sets_line, remained_text = get_text_till_substring(remained_text, \"EDGE_WEIGHT_TYPE\")\n",
    "    # === EDGE_WEIGHT_TYPE ==\n",
    "    sop_lines.edge_weight_type_line, remained_text = get_text_till_substring(remained_text, \"NODE_COORD_SECTION\")\n",
    "    # === NODE_COORD_SECTION ==\n",
    "    sop_lines.node_coord_section_line, remained_text = get_text_till_substring(remained_text, \"GTSP_SET_SECTION\")\n",
    "    # === GTSP_SET_SECTION ==\n",
    "    sop_lines.gtsp_set_section_line = remained_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    for t_value in t_values:\n",
    "        sop_datasets_to_transform = glob.glob(f\"./SOP_non_random_datasets/*T{t_value}*\")\n",
    "        for sop_dataset in sop_datasets_to_transform:\n",
    "            transform_dataset(sop_dataset, t_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_100_t_values = [120, 140, 160, 180, 200]\n",
    "def create_datasets_over_100():\n",
    "    for t_value in over_100_t_values:\n",
    "        sop_datasets_to_transform = glob.glob(f\"./SOP_non_random_datasets/*T100*\")\n",
    "        for sop_dataset in sop_datasets_to_transform:\n",
    "            transform_dataset(sop_dataset, t_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'removeprefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-31620c1e6806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_datasets_over_100\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-620b1deb63b8>\u001b[0m in \u001b[0;36mcreate_datasets_over_100\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msop_datasets_to_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"./SOP_non_random_datasets/*T100*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msop_dataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msop_datasets_to_transform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtransform_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msop_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-990467c0f3b2>\u001b[0m in \u001b[0;36mtransform_dataset\u001b[1;34m(dataset_path, t_value)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtransform_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msop_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSOPDatasetLines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msplit_sop_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msop_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msop_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvehicles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvehicle_numbers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a7e848949683>\u001b[0m in \u001b[0;36msplit_sop_file\u001b[1;34m(dataset_path, sop_lines)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msop_f_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msop_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# === NAME ===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msop_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremained_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_text_till_substring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msop_f_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"TYPE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"COMMENT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# === TYPE, COMMENT ===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mremained_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TYPE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-fc8e2a453bc2>\u001b[0m in \u001b[0;36mget_text_till_substring\u001b[1;34m(text, delimeters)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mdelimeters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelimeters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtext_to_get\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelimeters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mremained_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremoveprefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_get\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext_to_get\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremained_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'removeprefix'"
     ]
    }
   ],
   "source": [
    "create_datasets_over_100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_values = [60, 80, 100]\n",
    "create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
